{
 "cells": [
  {
   "cell_type": "raw",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Trading Signal System - Data Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides analysis tools for the GNN-based trading signal system.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Standard imports\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from datetime import datetime, timedelta\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configure plotting\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 6)\\n\",\n",
    "    \"plt.rcParams['font.size'] = 12\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Project imports\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.utils.bigquery_client import BigQueryClient\\n\",\n",
    "    \"from src.training.metrics import ModelMetrics\\n\",\n",
    "    \"from src.feature_engineering.graph_constructor import StockGraphConstructor\\n\",\n",
    "    \"from config.settings import BQ_TABLES, load_stocks_config\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize clients\\n\",\n",
    "    \"bq_client = BigQueryClient()\\n\",\n",
    "    \"metrics_calculator = ModelMetrics()\\n\",\n",
    "    \"graph_constructor = StockGraphConstructor()\\n\",\n",
    "    \"stocks_config = load_stocks_config()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Clients initialized successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Data Quality Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check data availability\\n\",\n",
    "    \"query = f\\\"\\\"\\\"\\n\",\n",
    "    \"SELECT \\n\",\n",
    "    \"    'raw_ohlcv' as table_name,\\n\",\n",
    "    \"    COUNT(DISTINCT ticker) as unique_tickers,\\n\",\n",
    "    \"    COUNT(DISTINCT date) as unique_dates,\\n\",\n",
    "    \"    MIN(date) as min_date,\\n\",\n",
    "    \"    MAX(date) as max_date,\\n\",\n",
    "    \"    COUNT(*) as total_records\\n\",\n",
    "    \"FROM `{BQ_TABLES['raw_ohlcv']}`\\n\",\n",
    "    \"\\n\",\n",
    "    \"UNION ALL\\n\",\n",
    "    \"\\n\",\n",
    "    \"SELECT \\n\",\n",
    "    \"    'technical_indicators' as table_name,\\n\",\n",
    "    \"    COUNT(DISTINCT ticker) as unique_tickers,\\n\",\n",
    "    \"    COUNT(DISTINCT date) as unique_dates,\\n\",\n",
    "    \"    MIN(date) as min_date,\\n\",\n",
    "    \"    MAX(date) as max_date,\\n\",\n",
    "    \"    COUNT(*) as total_records\\n\",\n",
    "    \"FROM `{BQ_TABLES['technical_indicators']}`\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"data_summary = bq_client.query(query)\\n\",\n",
    "    \"data_summary\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data coverage heatmap\\n\",\n",
    "    \"query = f\\\"\\\"\\\"\\n\",\n",
    "    \"SELECT \\n\",\n",
    "    \"    ticker,\\n\",\n",
    "    \"    DATE_TRUNC(date, MONTH) as month,\\n\",\n",
    "    \"    COUNT(*) as trading_days\\n\",\n",
    "    \"FROM `{BQ_TABLES['raw_ohlcv']}`\\n\",\n",
    "    \"WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 12 MONTH)\\n\",\n",
    "    \"GROUP BY ticker, month\\n\",\n",
    "    \"ORDER BY ticker, month\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"coverage_df = bq_client.query(query)\\n\",\n",
    "    \"coverage_pivot = coverage_df.pivot(index='ticker', columns='month', values='trading_days')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(14, 10))\\n\",\n",
    "    \"sns.heatmap(coverage_pivot, cmap='YlOrRd', annot=True, fmt='g', cbar_kws={'label': 'Trading Days'})\\n\",\n",
    "    \"plt.title('Data Coverage by Ticker and Month')\\n\",\n",
    "    \"plt.xlabel('Month')\\n\",\n",
    "    \"plt.ylabel('Ticker')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Market Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Sector performance analysis\\n\",\n",
    "    \"query = f\\\"\\\"\\\"\\n\",\n",
    "    \"WITH price_changes AS (\\n\",\n",
    "    \"    SELECT \\n\",\n",
    "    \"        o.ticker,\\n\",\n",
    "    \"        s.sector,\\n\",\n",
    "    \"        o.date,\\n\",\n",
    "    \"        o.close,\\n\",\n",
    "    \"        LAG(o.close, 1) OVER (PARTITION BY o.ticker ORDER BY o.date) as prev_close,\\n\",\n",
    "    \"        (o.close - LAG(o.close, 1) OVER (PARTITION BY o.ticker ORDER BY o.date)) / \\n\",\n",
    "    \"        LAG(o.close, 1) OVER (PARTITION BY o.ticker ORDER BY o.date) as daily_return\\n\",\n",
    "    \"    FROM `{BQ_TABLES['raw_ohlcv']}` o\\n\",\n",
    "    \"    JOIN `{BQ_TABLES['stock_metadata']}` s\\n\",\n",
    "    \"    ON o.ticker = s.ticker\\n\",\n",
    "    \"    WHERE o.date >= DATE_SUB(CURRENT_DATE(), INTERVAL 90 DAY)\\n\",\n",
    "    \")\\n\",\n",
    "    \"SELECT \\n\",\n",
    "    \"    sector,\\n\",\n",
    "    \"    AVG(daily_return) * 252 as annualized_return,\\n\",\n",
    "    \"    STDDEV(daily_return) * SQRT(252) as annualized_volatility,\\n\",\n",
    "    \"    AVG(daily_return) / STDDEV(daily_return) * SQRT(252) as sharpe_ratio,\\n\",\n",
    "    \"    COUNT(DISTINCT ticker) as num_stocks\\n\",\n",
    "    \"FROM price_changes\\n\",\n",
    "    \"WHERE daily_return IS NOT NULL\\n\",\n",
    "    \"GROUP BY sector\\n\",\n",
    "    \"ORDER BY sharpe_ratio DESC\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"sector_performance = bq_client.query(query)\\n\",\n",
    "    \"sector_performance\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize sector performance\\n\",\n",
    "    \"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Return vs Volatility scatter\\n\",\n",
    "    \"ax1.scatter(sector_performance['annualized_volatility'], \\n\",\n",
    "    \"           sector_performance['annualized_return'],\\n\",\n",
    "    \"           s=sector_performance['num_stocks']*50,\\n\",\n",
    "    \"           alpha=0.6)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for idx, row in sector_performance.iterrows():\\n\",\n",
    "    \"    ax1.annotate(row['sector'], \\n\",\n",
    "    \"                (row['annualized_volatility'], row['annualized_return']),\\n\",\n",
    "    \"                fontsize=9)\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax1.set_xlabel('Annualized Volatility')\\n\",\n",
    "    \"ax1.set_ylabel('Annualized Return')\\n\",\n",
    "    \"ax1.set_title('Sector Risk-Return Profile')\\n\",\n",
    "    \"ax1.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sharpe ratio bar chart\\n\",\n",
    "    \"sector_performance.plot(x='sector', y='sharpe_ratio', kind='bar', ax=ax2)\\n\",\n",
    "    \"ax2.set_xlabel('Sector')\\n\",\n",
    "    \"ax2.set_ylabel('Sharpe Ratio')\\n\",\n",
    "    \"ax2.set_title('Sector Sharpe Ratios')\\n\",\n",
    "    \"ax2.axhline(y=0, color='r', linestyle='--', alpha=0.5)\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Feature Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Technical indicator distributions\\n\",\n",
    "    \"query = f\\\"\\\"\\\"\\n\",\n",
    "    \"SELECT \\n\",\n",
    "    \"    rsi,\\n\",\n",
    "    \"    macd,\\n\",\n",
    "    \"    atr / close * 100 as atr_percent,\\n\",\n",
    "    \"    adx,\\n\",\n",
    "    \"    (close - sma_20) / sma_20 * 100 as price_vs_sma20\\n\",\n",
    "    \"FROM `{BQ_TABLES['technical_indicators']}` t\\n\",\n",
    "    \"JOIN `{BQ_TABLES['raw_ohlcv']}` o\\n\",\n",
    "    \"ON t.ticker = o.ticker AND t.date = o.date\\n\",\n",
    "    \"WHERE t.date >= DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)\\n\",\n",
    "    \"  AND rsi IS NOT NULL\\n\",\n",
    "    \"  AND macd IS NOT NULL\\n\",\n",
    "    \"LIMIT 10000\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"indicators_df = bq_client.query(query)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create distribution plots\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 3, figsize=(15, 10))\\n\",\n",
    "    \"axes = axes.ravel()\\n\",\n",
    "    \"\\n\",\n",
    "    \"indicators = ['rsi', 'macd', 'atr_percent', 'adx', 'price_vs_sma20']\\n\",\n",
    "    \"for i, indicator in enumerate(indicators):\\n\",\n",
    "    \"    axes[i].hist(indicators_df[indicator].dropna(), bins=50, alpha=0.7, edgecolor='black')\\n\",\n",
    "    \"    axes[i].set_title(f'{indicator.upper()} Distribution')\\n\",\n",
    "    \"    axes[i].set_xlabel(indicator)\\n\",\n",
    "    \"    axes[i].set_ylabel('Frequency')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add mean line\\n\",\n",
    "    \"    mean_val = indicators_df[indicator].mean()\\n\",\n",
    "    \"    axes[i].axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\\n\",\n",
    "    \"    axes[i].legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Remove empty subplot\\n\",\n",
    "    \"fig.delaxes(axes[5])\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Graph Structure Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Build and analyze graph structure\\n\",\n",
    "    \"end_date = datetime.now().strftime('%Y-%m-%d')\\n\",\n",
    "    \"start_date = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')\\n\",\n",
    "    \"\\n\",\n",
    "    \"graph_structure = graph_constructor.build_graph(start_date, end_date)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate graph statistics\\n\",\n",
    "    \"import networkx as nx\\n\",\n",
    "    \"\\n\",\n",
    "    \"G = nx.Graph()\\n\",\n",
    "    \"for source, targets in graph_structure.items():\\n\",\n",
    "    \"    for target, weight in targets.items():\\n\",\n",
    "    \"        G.add_edge(source, target, weight=weight)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Number of nodes: {G.number_of_nodes()}\\\")\\n\",\n",
    "    \"print(f\\\"Number of edges: {G.number_of_edges()}\\\")\\n\",\n",
    "    \"print(f\\\"Average degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Graph density: {nx.density(G):.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Average clustering coefficient: {nx.average_clustering(G):.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize a subgraph\\n\",\n",
    "    \"tech_stocks = ['AAPL', 'MSFT', 'GOOGL', 'NVDA']\\n\",\n",
    "    \"subgraph = graph_constructor.get_subgraph(graph_structure, 'AAPL', max_distance=2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create visualization\\n\",\n",
    "    \"graph_constructor.visualize_graph(\\n\",\n",
    "    \"    subgraph,\\n\",\n",
    "    \"    output_file='apple_network.png',\\n\",\n",
    "    \"    show_labels=True\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Graph visualization saved to apple_network.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Model Performance Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load prediction history\\n\",\n",
    "    \"query = f\\\"\\\"\\\"\\n\",\n",
    "    \"WITH predictions_actuals AS (\\n\",\n",
    "    \"    SELECT \\n\",\n",
    "    \"        p.ticker,\\n\",\n",
    "    \"        p.prediction_date,\\n\",\n",
    "    \"        p.horizon_7d as prediction,\\n\",\n",
    "    \"        p.confidence_7d as confidence,\\n\",\n",
    "    \"        (LEAD(o.close, 7) OVER (PARTITION BY o.ticker ORDER BY o.date) - o.close) / o.close as actual_7d\\n\",\n",
    "    \"    FROM `{BQ_TABLES['predictions']}` p\\n\",\n",
    "    \"    JOIN `{BQ_TABLES['raw_ohlcv']}` o\\n\",\n",
    "    \"    ON p.ticker = o.ticker AND p.prediction_date = o.date\\n\",\n",
    "    \"    WHERE p.prediction_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 90 DAY)\\n\",\n",
    "    \")\\n\",\n",
    "    \"SELECT *\\n\",\n",
    "    \"FROM predictions_actuals\\n\",\n",
    "    \"WHERE actual_7d IS NOT NULL\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"predictions_df = bq_client.query(query)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not predictions_df.empty:\\n\",\n",
    "    \"    # Calculate metrics\\n\",\n",
    "    \"    metrics = metrics_calculator.calculate_metrics(\\n\",\n",
    "    \"        predictions_df['prediction'].values,\\n\",\n",
    "    \"        predictions_df['actual_7d'].values,\\n\",\n",
    "    \"        predictions_df['confidence'].values\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"Model Performance Metrics (7-day horizon):\\\")\\n\",\n",
    "    \"    for metric, value in sorted(metrics.items()):\\n\",\n",
    "    \"        print(f\\\"{metric:25}: {value:10.4f}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No prediction data available for analysis\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Prediction accuracy by confidence level\\n\",\n",
    "    \"if not predictions_df.empty:\\n\",\n",
    "    \"    # Bin by confidence\\n\",\n",
    "    \"    predictions_df['confidence_bin'] = pd.cut(\\n\",\n",
    "    \"        predictions_df['confidence'], \\n\",\n",
    "    \"        bins=[0, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\\n\",\n",
    "    \"        labels=['<50%', '50-60%', '60-70%', '70-80%', '80-90%', '>90%']\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate accuracy by bin\\n\",\n",
    "    \"    accuracy_by_confidence = predictions_df.groupby('confidence_bin').apply(\\n\",\n",
    "    \"        lambda x: np.mean(np.sign(x['prediction']) == np.sign(x['actual_7d']))\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot\\n\",\n",
    "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"    accuracy_by_confidence.plot(kind='bar')\\n\",\n",
    "    \"    plt.axhline(y=0.5, color='r', linestyle='--', label='Random (50%)')\\n\",\n",
    "    \"    plt.xlabel('Confidence Level')\\n\",\n",
    "    \"    plt.ylabel('Direction Accuracy')\\n\",\n",
    "    \"    plt.title('Prediction Accuracy by Confidence Level')\\n\",\n",
    "    \"    plt.legend()\\n\",\n",
    "    \"    plt.xticks(rotation=45)\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Trading Signal Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze top signals\\n\",\n",
    "    \"if not predictions_df.empty:\\n\",\n",
    "    \"    # Get latest predictions\\n\",\n",
    "    \"    latest_date = predictions_df['prediction_date'].max()\\n\",\n",
    "    \"    latest_predictions = predictions_df[predictions_df['prediction_date'] == latest_date]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Filter high confidence predictions\\n\",\n",
    "    \"    high_confidence = latest_predictions[latest_predictions['confidence'] > 0.7]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Sort by absolute prediction value\\n\",\n",
    "    \"    high_confidence['abs_prediction'] = high_confidence['prediction'].abs()\\n\",\n",
    "    \"    top_signals = high_confidence.nlargest(10, 'abs_prediction')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nTop 10 Trading Signals for {latest_date}:\\\")\\n\",\n",
    "    \"    print(\\\"=\\\" * 60)\\n\",\n",
    "    \"    for _, signal in top_signals.iterrows():\\n\",\n",
    "    \"        direction = \\\"BUY\\\" if signal['prediction'] > 0 else \\\"SELL\\\"\\n\",\n",
    "    \"        print(f\\\"{signal['ticker']:6} {direction:4} | \\\"\\n\",\n",
    "    \"              f\\\"Return: {signal['prediction']*100:6.2f}% | \\\"\\n\",\n",
    "    \"              f\\\"Confidence: {signal['confidence']:.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Portfolio construction example\\n\",\n",
    "    \"if not predictions_df.empty and len(top_signals) > 0:\\n\",\n",
    "    \"    # Simple equal weight portfolio from top signals\\n\",\n",
    "    \"    portfolio_size = min(5, len(top_signals))\\n\",\n",
    "    \"    portfolio = top_signals.head(portfolio_size)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate expected portfolio return\\n\",\n",
    "    \"    portfolio_return = portfolio['prediction'].mean()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nSample Portfolio Construction:\\\")\\n\",\n",
    "    \"    print(\\\"=\\\" * 40)\\n\",\n",
    "    \"    print(f\\\"Number of positions: {portfolio_size}\\\")\\n\",\n",
    "    \"    print(f\\\"Expected return (7d): {portfolio_return*100:.2f}%\\\")\\n\",\n",
    "    \"    print(\\\"\\\\nPositions:\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for _, pos in portfolio.iterrows():\\n\",\n",
    "    \"        weight = 1.0 / portfolio_size\\n\",\n",
    "    \"        print(f\\\"{pos['ticker']:6} | Weight: {weight*100:5.1f}% | \\\"\\n\",\n",
    "    \"              f\\\"Expected: {pos['prediction']*100:6.2f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Risk Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Correlation matrix of selected stocks\\n\",\n",
    "    \"selected_tickers = ['AAPL', 'MSFT', 'JPM', 'XOM', 'AMZN']\\n\",\n",
    "    \"\\n\",\n",
    "    \"query = f\\\"\\\"\\\"\\n\",\n",
    "    \"SELECT \\n\",\n",
    "    \"    ticker,\\n\",\n",
    "    \"    date,\\n\",\n",
    "    \"    close\\n\",\n",
    "    \"FROM `{BQ_TABLES['raw_ohlcv']}`\\n\",\n",
    "    \"WHERE ticker IN {tuple(selected_tickers)}\\n\",\n",
    "    \"  AND date >= DATE_SUB(CURRENT_DATE(), INTERVAL 180 DAY)\\n\",\n",
    "    \"ORDER BY ticker, date\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"price_data = bq_client.query(query)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate returns\\n\",\n",
    "    \"returns_df = price_data.pivot(index='date', columns='ticker', values='close').pct_change()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Correlation matrix\\n\",\n",
    "    \"corr_matrix = returns_df.corr()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize\\n\",\n",
    "    \"plt.figure(figsize=(8, 6))\\n\",\n",
    "    \"sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \\n\",\n",
    "    \"            square=True, linewidths=1, cbar_kws={\\\"shrink\\\": 0.8})\\n\",\n",
    "    \"plt.title('Stock Return Correlations (180 days)')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Risk metrics by sector\\n\",\n",
    "    \"query = f\\\"\\\"\\\"\\n\",\n",
    "    \"WITH returns AS (\\n\",\n",
    "    \"    SELECT \\n\",\n",
    "    \"        s.sector,\\n\",\n",
    "    \"        o.ticker,\\n\",\n",
    "    \"        o.date,\\n\",\n",
    "    \"        (o.close - LAG(o.close) OVER (PARTITION BY o.ticker ORDER BY o.date)) / \\n\",\n",
    "    \"        LAG(o.close) OVER (PARTITION BY o.ticker ORDER BY o.date) as daily_return\\n\",\n",
    "    \"    FROM `{BQ_TABLES['raw_ohlcv']}` o\\n\",\n",
    "    \"    JOIN `{BQ_TABLES['stock_metadata']}` s\\n\",\n",
    "    \"    ON o.ticker = s.ticker\\n\",\n",
    "    \"    WHERE o.date >= DATE_SUB(CURRENT_DATE(), INTERVAL 180 DAY)\\n\",\n",
    "    \")\\n\",\n",
    "    \"SELECT \\n\",\n",
    "    \"    sector,\\n\",\n",
    "    \"    STDDEV(daily_return) * SQRT(252) as annualized_vol,\\n\",\n",
    "    \"    APPROX_QUANTILES(daily_return, 100)[OFFSET(5)] as var_95,\\n\",\n",
    "    \"    APPROX_QUANTILES(daily_return, 100)[OFFSET(1)] as var_99,\\n\",\n",
    "    \"    MIN(daily_return) as worst_day,\\n\",\n",
    "    \"    MAX(daily_return) as best_day\\n\",\n",
    "    \"FROM returns\\n\",\n",
    "    \"WHERE daily_return IS NOT NULL\\n\",\n",
    "    \"GROUP BY sector\\n\",\n",
    "    \"ORDER BY annualized_vol DESC\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"risk_metrics = bq_client.query(query)\\n\",\n",
    "    \"risk_metrics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Summary and Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Findings:\\n\",\n",
    "    \"1. Data coverage and quality\\n\",\n",
    "    \"2. Sector performance characteristics\\n\",\n",
    "    \"3. Model prediction accuracy\\n\",\n",
    "    \"4. Risk-return profiles\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Recommendations:\\n\",\n",
    "    \"1. Focus on high-confidence predictions\\n\",\n",
    "    \"2. Diversify across sectors\\n\",\n",
    "    \"3. Monitor model performance regularly\\n\",\n",
    "    \"4. Implement proper risk management\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save analysis results\\n\",\n",
    "    \"analysis_date = datetime.now().strftime('%Y%m%d')\\n\",\n",
    "    \"print(f\\\"Analysis completed on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\\")\\n\",\n",
    "    \"print(f\\\"Results can be exported for further analysis\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
